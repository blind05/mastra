/**
 * Auto-generated provider registry from models.dev API
 * Generated on: 2025-09-11T01:18:02.069Z
 * 
 * DO NOT EDIT MANUALLY - This file is auto-generated by scripts/generate-providers.mjs
 */

export interface ProviderConfig {
  url: string;
  defaultHeaders?: Record<string, string>;
  apiKeyEnvVar?: string;
  apiKeyHeader?: string;
  name?: string;
  models?: readonly string[];
}

/**
 * Registry of OpenAI-compatible providers
 */
export const PROVIDER_REGISTRY = {
  "deepseek": {
    "url": "https://api.deepseek.com/v1/chat/completions",
    "apiKeyEnvVar": "DEEPSEEK_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "DeepSeek",
    "models": [
      "deepseek-reasoner",
      "deepseek-chat"
    ]
  },
  "fireworks_ai": {
    "url": "https://api.fireworks.ai/inference/v1/chat/completions",
    "apiKeyEnvVar": "FIREWORKS_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Fireworks AI",
    "models": [
      "accounts/fireworks/gpt-oss-20b",
      "accounts/fireworks/gpt-oss-120b",
      "accounts/fireworks/models/qwen3-235b-a22b",
      "accounts/fireworks/models/deepseek-v3-0324",
      "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
      "accounts/fireworks/models/deepseek-r1-0528",
      "accounts/fireworks/models/glm-4p5-air",
      "accounts/fireworks/models/kimi-k2-instruct",
      "accounts/fireworks/models/glm-4p5",
      "accounts/fireworks/models/deepseek-v3p1"
    ]
  },
  "openrouter": {
    "url": "https://openrouter.ai/api/v1/chat/completions",
    "apiKeyEnvVar": "OPENROUTER_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "OpenRouter",
    "models": [
      "deepseek/deepseek-r1-0528:free",
      "deepseek/deepseek-chat-v3.1",
      "deepseek/deepseek-r1-distill-llama-70b",
      "deepseek/deepseek-v3-base:free",
      "deepseek/deepseek-r1-0528-qwen3-8b:free",
      "deepseek/deepseek-chat-v3-0324",
      "deepseek/deepseek-r1:free",
      "deepseek/deepseek-r1-distill-qwen-14b",
      "rekaai/reka-flash-3",
      "featherless/qwerky-72b",
      "openrouter/horizon-beta",
      "openrouter/cypher-alpha:free",
      "openrouter/sonoma-dusk-alpha",
      "openrouter/sonoma-sky-alpha",
      "openrouter/horizon-alpha",
      "anthropic/claude-sonnet-4",
      "anthropic/claude-opus-4",
      "anthropic/claude-3.5-haiku",
      "anthropic/claude-opus-4.1",
      "anthropic/claude-3.7-sonnet",
      "openai/gpt-5-nano",
      "openai/gpt-4.1",
      "openai/gpt-oss-20b",
      "openai/gpt-5",
      "openai/gpt-5-chat",
      "openai/gpt-5-mini",
      "openai/gpt-4o-mini",
      "openai/gpt-4.1-mini",
      "openai/gpt-oss-120b",
      "openai/o4-mini",
      "thudm/glm-z1-32b:free",
      "sarvamai/sarvam-m:free",
      "x-ai/grok-code-fast-1",
      "x-ai/grok-3-mini-beta",
      "x-ai/grok-3",
      "x-ai/grok-3-mini",
      "x-ai/grok-4",
      "x-ai/grok-3-beta",
      "mistralai/codestral-2508",
      "mistralai/mistral-medium-3",
      "mistralai/devstral-small-2505",
      "mistralai/mistral-small-3.2-24b-instruct:free",
      "mistralai/devstral-medium-2507",
      "mistralai/mistral-small-3.2-24b-instruct",
      "mistralai/devstral-small-2507",
      "mistralai/mistral-nemo:free",
      "mistralai/mistral-small-3.1-24b-instruct",
      "mistralai/mistral-7b-instruct:free",
      "mistralai/mistral-medium-3.1",
      "mistralai/devstral-small-2505:free",
      "meta-llama/llama-4-scout:free",
      "meta-llama/llama-3.2-11b-vision-instruct",
      "meta-llama/llama-3.3-70b-instruct:free",
      "google/gemini-2.5-pro",
      "google/gemma-3-12b-it",
      "google/gemini-2.0-flash-001",
      "google/gemini-2.0-flash-exp:free",
      "google/gemma-3n-e4b-it:free",
      "google/gemma-2-9b-it:free",
      "google/gemini-2.5-flash",
      "google/gemini-2.5-pro-preview-06-05",
      "google/gemini-2.5-pro-preview-05-06",
      "google/gemma-3n-e4b-it",
      "google/gemma-3-27b-it",
      "microsoft/mai-ds-r1:free",
      "z-ai/glm-4.5-air:free",
      "z-ai/glm-4.5-air",
      "z-ai/glm-4.5v",
      "z-ai/glm-4.5",
      "cognitivecomputations/dolphin3.0-mistral-24b",
      "cognitivecomputations/dolphin3.0-r1-mistral-24b",
      "qwen/qwen2.5-vl-72b-instruct",
      "qwen/qwen3-coder:free",
      "qwen/qwen3-235b-a22b-thinking-2507",
      "qwen/qwen3-30b-a3b:free",
      "qwen/qwen3-32b:free",
      "qwen/qwen3-max",
      "qwen/qwen3-235b-a22b:free",
      "qwen/qwen3-30b-a3b-instruct-2507",
      "qwen/qwen-2.5-coder-32b-instruct",
      "qwen/qwen2.5-vl-72b-instruct:free",
      "qwen/qwen3-235b-a22b-07-25:free",
      "qwen/qwq-32b:free",
      "qwen/qwen2.5-vl-32b-instruct:free",
      "qwen/qwen3-coder",
      "qwen/qwen3-8b:free",
      "qwen/qwen3-235b-a22b-07-25",
      "qwen/qwen3-14b:free",
      "tngtech/deepseek-r1t2-chimera:free",
      "nousresearch/hermes-4-405b",
      "nousresearch/hermes-4-70b",
      "nousresearch/deephermes-3-llama-3-8b-preview",
      "moonshotai/kimi-k2-0905",
      "moonshotai/kimi-k2:free",
      "moonshotai/kimi-k2",
      "moonshotai/kimi-dev-72b:free"
    ]
  },
  "venice": {
    "url": "https://api.venice.ai/api/v1/chat/completions",
    "apiKeyEnvVar": "VENICE_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Venice AI",
    "models": [
      "qwen-2.5-coder-32b",
      "venice-uncensored",
      "deepseek-coder-v2-lite",
      "dolphin-2.9.2-qwen2-72b",
      "qwen3-4b",
      "qwen-2.5-vl",
      "llama-3.3-70b",
      "llama-3.1-405b",
      "llama-3.2-3b",
      "deepseek-r1-671b",
      "qwen-2.5-qwq-32b",
      "qwen3-235b",
      "mistral-31-24b"
    ]
  },
  "github_copilot": {
    "url": "https://api.githubcopilot.com/v1/chat/completions",
    "apiKeyEnvVar": "GITHUB_TOKEN",
    "apiKeyHeader": "Authorization",
    "name": "GitHub Copilot",
    "models": [
      "gemini-2.5-pro",
      "claude-sonnet-4",
      "gpt-4.1",
      "gemini-2.0-flash-001",
      "claude-opus-4",
      "grok-code-fast-1",
      "claude-opus-41",
      "claude-3.7-sonnet-thought",
      "gpt-5",
      "o3",
      "gpt-5-mini",
      "claude-3.7-sonnet",
      "claude-3.5-sonnet",
      "gpt-4o",
      "o4-mini",
      "o3-mini"
    ]
  },
  "submodel": {
    "url": "https://llm.submodel.ai/v1/chat/completions",
    "apiKeyEnvVar": "SUBMODEL_INSTAGEN_ACCESS_KEY",
    "apiKeyHeader": "Authorization",
    "name": "submodel",
    "models": [
      "deepseek-ai/DeepSeek-V3.1",
      "deepseek-ai/DeepSeek-V3-0324",
      "deepseek-ai/DeepSeek-R1-0528",
      "openai/gpt-oss-120b",
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "zai-org/GLM-4.5-FP8",
      "zai-org/GLM-4.5-Air"
    ]
  },
  "alibaba": {
    "url": "https://dashscope-intl.aliyuncs.com/compatible-mode/v1/chat/completions",
    "apiKeyEnvVar": "DASHSCOPE_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Alibaba",
    "models": [
      "qwen3-coder-plus"
    ]
  },
  "upstage": {
    "url": "https://api.upstage.ai/v1/chat/completions",
    "apiKeyEnvVar": "UPSTAGE_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Upstage",
    "models": [
      "solar-pro2",
      "solar-mini"
    ]
  },
  "llama": {
    "url": "https://api.llama.com/compat/v1/chat/completions",
    "apiKeyEnvVar": "LLAMA_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Llama",
    "models": [
      "groq-llama-4-maverick-17b-128e-instruct",
      "llama-3.3-70b-instruct",
      "llama-4-maverick-17b-128e-instruct-fp8",
      "llama-4-scout-17b-16e-instruct-fp8",
      "cerebras-llama-4-scout-17b-16e-instruct",
      "llama-3.3-8b-instruct",
      "cerebras-llama-4-maverick-17b-128e-instruct"
    ]
  },
  "moonshotai_cn": {
    "url": "https://api.moonshot.cn/v1/chat/completions",
    "apiKeyEnvVar": "MOONSHOT_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Moonshot AI (China)",
    "models": [
      "kimi-k2-0905-preview",
      "kimi-k2-0711-preview",
      "kimi-k2-turbo-preview"
    ]
  },
  "zhipuai": {
    "url": "https://open.bigmodel.cn/api/paas/v4/v1/chat/completions",
    "apiKeyEnvVar": "ZHIPU_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Zhipu AI",
    "models": [
      "glm-4.5",
      "glm-4.5-flash",
      "glm-4.5v",
      "glm-4.5-air"
    ]
  },
  "synthetic": {
    "url": "https://api.synthetic.new/v1/chat/completions",
    "apiKeyEnvVar": "SYNTHETIC_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Synthetic",
    "models": [
      "hf:meta-llama/Llama-3.1-405B-Instruct",
      "hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "hf:meta-llama/Llama-3.1-70B-Instruct",
      "hf:meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "hf:meta-llama/Llama-3.3-70B-Instruct",
      "hf:meta-llama/Llama-3.1-8B-Instruct",
      "hf:deepseek-ai/DeepSeek-V3.1",
      "hf:deepseek-ai/DeepSeek-V3",
      "hf:deepseek-ai/DeepSeek-V3-0324",
      "hf:deepseek-ai/DeepSeek-R1",
      "hf:deepseek-ai/DeepSeek-R1-0528",
      "hf:zai-org/GLM-4.5",
      "hf:moonshotai/Kimi-K2-Instruct",
      "hf:moonshotai/Kimi-K2-Instruct-0905",
      "hf:Qwen/Qwen2.5-Coder-32B-Instruct",
      "hf:Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "hf:Qwen/Qwen3-235B-A22B-Thinking-2507",
      "hf:Qwen/Qwen3-235B-A22B-Instruct-2507",
      "hf:openai/gpt-oss-120b"
    ]
  },
  "modelscope": {
    "url": "https://api-inference.modelscope.cn/v1/chat/completions",
    "apiKeyEnvVar": "MODELSCOPE_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "ModelScope",
    "models": [
      "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "ZhipuAI/GLM-4.5",
      "moonshotai/Kimi-K2-Instruct"
    ]
  },
  "baseten": {
    "url": "https://inference.baseten.co/v1/chat/completions",
    "apiKeyEnvVar": "BASETEN_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Baseten",
    "models": [
      "Moonshotai-Kimi-K2-Instruct-0905",
      "Qwen-Qwen3-Coder-480B-A35B-Instruct"
    ]
  },
  "wandb": {
    "url": "https://api.inference.wandb.ai/v1/chat/completions",
    "apiKeyEnvVar": "WANDB_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Weights & Biases",
    "models": [
      "deepseek-ai/DeepSeek-V3-0324",
      "deepseek-ai/DeepSeek-R1-0528",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "meta-llama/Llama-3.3-70B-Instruct",
      "meta-llama/Llama-3.1-8B-Instruct",
      "microsoft/Phi-4-mini-instruct",
      "moonshotai/Kimi-K2-Instruct"
    ]
  },
  "inference": {
    "url": "https://inference.net/v1/chat/completions",
    "apiKeyEnvVar": "INFERENCE_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Inference",
    "models": [
      "meta/llama-3.2-3b-instruct",
      "meta/llama-3.2-1b-instruct",
      "meta/llama-3.1-8b-instruct",
      "meta/llama-3.2-11b-vision-instruct",
      "mistral/mistral-nemo-12b-instruct",
      "google/gemma-3",
      "osmosis/osmosis-structure-0.6b",
      "qwen/qwen-2.5-7b-vision-instruct",
      "qwen/qwen3-embedding-4b"
    ]
  },
  "github_models": {
    "url": "https://models.github.ai/inference/v1/chat/completions",
    "apiKeyEnvVar": "GITHUB_TOKEN",
    "apiKeyHeader": "Authorization",
    "name": "GitHub Models",
    "models": [
      "deepseek/deepseek-v3-0324",
      "deepseek/deepseek-r1-0528",
      "deepseek/deepseek-r1",
      "meta/meta-llama-3-8b-instruct",
      "meta/llama-3.2-90b-vision-instruct",
      "meta/llama-3.3-70b-instruct",
      "meta/meta-llama-3.1-70b-instruct",
      "meta/llama-4-maverick-17b-128e-instruct-fp8",
      "meta/meta-llama-3.1-8b-instruct",
      "meta/meta-llama-3.1-405b-instruct",
      "meta/llama-3.2-11b-vision-instruct",
      "meta/llama-4-scout-17b-16e-instruct",
      "meta/meta-llama-3-70b-instruct",
      "xai/grok-3",
      "xai/grok-3-mini",
      "openai/gpt-4.1",
      "openai/o1",
      "openai/o3",
      "openai/o1-preview",
      "openai/gpt-4o-mini",
      "openai/gpt-4.1-nano",
      "openai/gpt-4.1-mini",
      "openai/o1-mini",
      "openai/gpt-4o",
      "openai/o4-mini",
      "openai/o3-mini",
      "ai21-labs/ai21-jamba-1.5-mini",
      "ai21-labs/ai21-jamba-1.5-large",
      "microsoft/phi-3-medium-4k-instruct",
      "microsoft/phi-3.5-vision-instruct",
      "microsoft/phi-4-reasoning",
      "microsoft/phi-4",
      "microsoft/phi-3-small-8k-instruct",
      "microsoft/phi-4-mini-instruct",
      "microsoft/phi-3-mini-128k-instruct",
      "microsoft/phi-3-small-128k-instruct",
      "microsoft/mai-ds-r1",
      "microsoft/phi-3.5-moe-instruct",
      "microsoft/phi-4-multimodal-instruct",
      "microsoft/phi-4-mini-reasoning",
      "microsoft/phi-3.5-mini-instruct",
      "microsoft/phi-3-mini-4k-instruct",
      "microsoft/phi-3-medium-128k-instruct",
      "mistral-ai/mistral-small-2503",
      "mistral-ai/mistral-large-2411",
      "mistral-ai/mistral-medium-2505",
      "mistral-ai/ministral-3b",
      "mistral-ai/mistral-nemo",
      "mistral-ai/codestral-2501",
      "cohere/cohere-command-r-08-2024",
      "cohere/cohere-command-r-plus-08-2024",
      "cohere/cohere-command-a",
      "cohere/cohere-command-r",
      "cohere/cohere-command-r-plus",
      "core42/jais-30b-chat"
    ]
  },
  "opencode": {
    "url": "https://opencode.ai/zen/v1/chat/completions",
    "apiKeyEnvVar": "OPENCODE_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "opencode",
    "models": [
      "claude-sonnet-4",
      "grok-code",
      "gpt-5",
      "claude-3.5-haiku",
      "kimi-k2",
      "claude-opus-4.1",
      "qwen3-coder"
    ]
  },
  "nvidia": {
    "url": "https://integrate.api.nvidia.com/v1/chat/completions",
    "apiKeyEnvVar": "NVIDIA_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Nvidia",
    "models": [
      "mistral-small-3.1-24b-instruct-2503",
      "llama-3.3-nemotron-super-49b-v1.5",
      "qwen3-235b-a22b",
      "deepseek-v3.1",
      "flux_1-dev",
      "cosmos-nemotron-34b",
      "whisper-large-v3",
      "qwen3-coder-480b-a35b-instruct",
      "phi-4-multimodal-instruct",
      "parakeet-tdt-0.6b-v2",
      "llama-3.1-nemotron-ultra-253b-v1",
      "deepseek-r1",
      "nemoretriever-ocr-v1",
      "gemma-3-27b-it"
    ]
  },
  "huggingface": {
    "url": "https://router.huggingface.co/v1/chat/completions",
    "apiKeyEnvVar": "HF_TOKEN",
    "apiKeyHeader": "Authorization",
    "name": "Hugging Face",
    "models": [
      "deepseek-ai/Deepseek-V3-0324",
      "deepseek-ai/DeepSeek-R1-0528",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "zai-org/GLM-4.5-Air",
      "zai-org/GLM-4.5",
      "moonshotai/Kimi-K2-Instruct"
    ]
  },
  "inception": {
    "url": "https://api.inceptionlabs.ai/v1/chat/completions",
    "apiKeyEnvVar": "INCEPTION_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Inception",
    "models": [
      "mercury-coder",
      "mercury"
    ]
  },
  "chutes": {
    "url": "https://llm.chutes.ai/v1/chat/completions",
    "apiKeyEnvVar": "CHUTES_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Chutes",
    "models": [
      "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "deepseek-ai/DeepSeek-V3.1",
      "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
      "deepseek-ai/DeepSeek-V3.1:THINKING",
      "deepseek-ai/DeepSeek-V3-0324",
      "deepseek-ai/DeepSeek-R1-0528",
      "openai/gpt-oss-120b",
      "chutesai/Devstral-Small-2505",
      "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "Qwen/Qwen3-30B-A3B",
      "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "zai-org/GLM-4.5-FP8",
      "zai-org/GLM-4.5-Air",
      "tngtech/DeepSeek-TNG-R1T2-Chimera",
      "tngtech/DeepSeek-R1T-Chimera",
      "moonshotai/Kimi-K2-Instruct-75k",
      "moonshotai/Kimi-VL-A3B-Thinking",
      "moonshotai/Kimi-K2-Instruct-0905",
      "moonshotai/Kimi-Dev-72B"
    ]
  },
  "lmstudio": {
    "url": "http://127.0.0.1:1234/v1/chat/completions",
    "apiKeyEnvVar": "LMSTUDIO_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "LMStudio",
    "models": [
      "openai/gpt-oss-20b",
      "qwen/qwen3-coder-30b",
      "qwen/qwen3-30b-a3b-2507"
    ]
  },
  "zai": {
    "url": "https://api.z.ai/api/paas/v4/v1/chat/completions",
    "apiKeyEnvVar": "ZHIPU_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Z.AI",
    "models": [
      "glm-4.5-air",
      "glm-4.5v",
      "glm-4.5-flash",
      "glm-4.5"
    ]
  },
  "fastrouter": {
    "url": "https://go.fastrouter.ai/api/v1/chat/completions",
    "apiKeyEnvVar": "FASTROUTER_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "FastRouter",
    "models": [
      "deepseek-ai/deepseek-r1-distill-llama-70b",
      "anthropic/claude-sonnet-4",
      "anthropic/claude-opus-4.1",
      "openai/gpt-5-nano",
      "openai/gpt-4.1",
      "openai/gpt-oss-20b",
      "openai/gpt-5",
      "openai/gpt-5-mini",
      "openai/gpt-oss-120b",
      "x-ai/grok-4",
      "google/gemini-2.5-pro",
      "google/gemini-2.5-flash",
      "qwen/qwen3-coder",
      "moonshotai/kimi-k2"
    ]
  },
  "morph": {
    "url": "https://api.morphllm.com/v1/chat/completions",
    "apiKeyEnvVar": "MORPH_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Morph",
    "models": [
      "auto",
      "morph-v3-fast",
      "morph-v3-large"
    ]
  },
  "moonshotai": {
    "url": "https://api.moonshot.ai/v1/chat/completions",
    "apiKeyEnvVar": "MOONSHOT_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Moonshot AI",
    "models": [
      "kimi-k2-turbo-preview",
      "kimi-k2-0711-preview",
      "kimi-k2-0905-preview"
    ]
  },
  "openai": {
    "url": "https://api.openai.com/v1/chat/completions",
    "apiKeyEnvVar": "OPENAI_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "OpenAI",
    "models": [
      "gpt-5-nano",
      "o3-pro",
      "codex-mini-latest",
      "gpt-4.1",
      "gpt-4-turbo",
      "o1",
      "o3-deep-research",
      "gpt-5",
      "o1-pro",
      "o3",
      "gpt-5-chat-latest",
      "gpt-5-mini",
      "o1-preview",
      "o4-mini-deep-research",
      "gpt-4o-mini",
      "gpt-4.1-nano",
      "gpt-4.1-mini",
      "o1-mini",
      "gpt-4o",
      "gpt-4",
      "gpt-3.5-turbo",
      "o4-mini",
      "o3-mini"
    ]
  },
  "anthropic": {
    "url": "https://api.anthropic.com/v1/chat/completions",
    "apiKeyEnvVar": "ANTHROPIC_API_KEY",
    "apiKeyHeader": "x-api-key",
    "name": "Anthropic",
    "defaultHeaders": {
      "anthropic-version": "2023-06-01"
    },
    "models": [
      "claude-3-7-sonnet-20250219",
      "claude-opus-4-1-20250805",
      "claude-3-haiku-20240307",
      "claude-3-5-haiku-20241022",
      "claude-opus-4-20250514",
      "claude-3-5-sonnet-20241022",
      "claude-3-5-sonnet-20240620",
      "claude-3-sonnet-20240229",
      "claude-sonnet-4-20250514",
      "claude-3-opus-20240229"
    ]
  },
  "groq": {
    "url": "https://api.groq.com/openai/v1/chat/completions",
    "apiKeyEnvVar": "GROQ_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Groq",
    "models": [
      "llama-3.1-8b-instant",
      "qwen-qwq-32b",
      "llama3-70b-8192",
      "deepseek-r1-distill-llama-70b",
      "llama3-8b-8192",
      "gemma2-9b-it",
      "llama-3.3-70b-versatile",
      "mistral-saba-24b",
      "llama-guard-3-8b",
      "openai/gpt-oss-20b",
      "openai/gpt-oss-120b",
      "meta-llama/llama-guard-4-12b",
      "meta-llama/llama-4-maverick-17b-128e-instruct",
      "meta-llama/llama-4-scout-17b-16e-instruct",
      "qwen/qwen3-32b",
      "moonshotai/kimi-k2-instruct-0905",
      "moonshotai/kimi-k2-instruct"
    ]
  },
  "together": {
    "url": "https://api.together.xyz/v1/chat/completions",
    "apiKeyEnvVar": "TOGETHER_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Together AI",
    "models": []
  },
  "perplexity": {
    "url": "https://api.perplexity.ai/chat/completions",
    "apiKeyEnvVar": "PERPLEXITY_API_KEY",
    "apiKeyHeader": "Authorization",
    "name": "Perplexity",
    "models": []
  }
} as const;

/**
 * Available models for each provider as a const object for type inference
 */
export const PROVIDER_MODELS = {
  "deepseek": [
    "deepseek-reasoner",
    "deepseek-chat"
  ],
  "fireworks_ai": [
    "accounts/fireworks/gpt-oss-20b",
    "accounts/fireworks/gpt-oss-120b",
    "accounts/fireworks/models/qwen3-235b-a22b",
    "accounts/fireworks/models/deepseek-v3-0324",
    "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
    "accounts/fireworks/models/deepseek-r1-0528",
    "accounts/fireworks/models/glm-4p5-air",
    "accounts/fireworks/models/kimi-k2-instruct",
    "accounts/fireworks/models/glm-4p5",
    "accounts/fireworks/models/deepseek-v3p1"
  ],
  "openrouter": [
    "deepseek/deepseek-r1-0528:free",
    "deepseek/deepseek-chat-v3.1",
    "deepseek/deepseek-r1-distill-llama-70b",
    "deepseek/deepseek-v3-base:free",
    "deepseek/deepseek-r1-0528-qwen3-8b:free",
    "deepseek/deepseek-chat-v3-0324",
    "deepseek/deepseek-r1:free",
    "deepseek/deepseek-r1-distill-qwen-14b",
    "rekaai/reka-flash-3",
    "featherless/qwerky-72b",
    "openrouter/horizon-beta",
    "openrouter/cypher-alpha:free",
    "openrouter/sonoma-dusk-alpha",
    "openrouter/sonoma-sky-alpha",
    "openrouter/horizon-alpha",
    "anthropic/claude-sonnet-4",
    "anthropic/claude-opus-4",
    "anthropic/claude-3.5-haiku",
    "anthropic/claude-opus-4.1",
    "anthropic/claude-3.7-sonnet",
    "openai/gpt-5-nano",
    "openai/gpt-4.1",
    "openai/gpt-oss-20b",
    "openai/gpt-5",
    "openai/gpt-5-chat",
    "openai/gpt-5-mini",
    "openai/gpt-4o-mini",
    "openai/gpt-4.1-mini",
    "openai/gpt-oss-120b",
    "openai/o4-mini",
    "thudm/glm-z1-32b:free",
    "sarvamai/sarvam-m:free",
    "x-ai/grok-code-fast-1",
    "x-ai/grok-3-mini-beta",
    "x-ai/grok-3",
    "x-ai/grok-3-mini",
    "x-ai/grok-4",
    "x-ai/grok-3-beta",
    "mistralai/codestral-2508",
    "mistralai/mistral-medium-3",
    "mistralai/devstral-small-2505",
    "mistralai/mistral-small-3.2-24b-instruct:free",
    "mistralai/devstral-medium-2507",
    "mistralai/mistral-small-3.2-24b-instruct",
    "mistralai/devstral-small-2507",
    "mistralai/mistral-nemo:free",
    "mistralai/mistral-small-3.1-24b-instruct",
    "mistralai/mistral-7b-instruct:free",
    "mistralai/mistral-medium-3.1",
    "mistralai/devstral-small-2505:free",
    "meta-llama/llama-4-scout:free",
    "meta-llama/llama-3.2-11b-vision-instruct",
    "meta-llama/llama-3.3-70b-instruct:free",
    "google/gemini-2.5-pro",
    "google/gemma-3-12b-it",
    "google/gemini-2.0-flash-001",
    "google/gemini-2.0-flash-exp:free",
    "google/gemma-3n-e4b-it:free",
    "google/gemma-2-9b-it:free",
    "google/gemini-2.5-flash",
    "google/gemini-2.5-pro-preview-06-05",
    "google/gemini-2.5-pro-preview-05-06",
    "google/gemma-3n-e4b-it",
    "google/gemma-3-27b-it",
    "microsoft/mai-ds-r1:free",
    "z-ai/glm-4.5-air:free",
    "z-ai/glm-4.5-air",
    "z-ai/glm-4.5v",
    "z-ai/glm-4.5",
    "cognitivecomputations/dolphin3.0-mistral-24b",
    "cognitivecomputations/dolphin3.0-r1-mistral-24b",
    "qwen/qwen2.5-vl-72b-instruct",
    "qwen/qwen3-coder:free",
    "qwen/qwen3-235b-a22b-thinking-2507",
    "qwen/qwen3-30b-a3b:free",
    "qwen/qwen3-32b:free",
    "qwen/qwen3-max",
    "qwen/qwen3-235b-a22b:free",
    "qwen/qwen3-30b-a3b-instruct-2507",
    "qwen/qwen-2.5-coder-32b-instruct",
    "qwen/qwen2.5-vl-72b-instruct:free",
    "qwen/qwen3-235b-a22b-07-25:free",
    "qwen/qwq-32b:free",
    "qwen/qwen2.5-vl-32b-instruct:free",
    "qwen/qwen3-coder",
    "qwen/qwen3-8b:free",
    "qwen/qwen3-235b-a22b-07-25",
    "qwen/qwen3-14b:free",
    "tngtech/deepseek-r1t2-chimera:free",
    "nousresearch/hermes-4-405b",
    "nousresearch/hermes-4-70b",
    "nousresearch/deephermes-3-llama-3-8b-preview",
    "moonshotai/kimi-k2-0905",
    "moonshotai/kimi-k2:free",
    "moonshotai/kimi-k2",
    "moonshotai/kimi-dev-72b:free"
  ],
  "venice": [
    "qwen-2.5-coder-32b",
    "venice-uncensored",
    "deepseek-coder-v2-lite",
    "dolphin-2.9.2-qwen2-72b",
    "qwen3-4b",
    "qwen-2.5-vl",
    "llama-3.3-70b",
    "llama-3.1-405b",
    "llama-3.2-3b",
    "deepseek-r1-671b",
    "qwen-2.5-qwq-32b",
    "qwen3-235b",
    "mistral-31-24b"
  ],
  "github_copilot": [
    "gemini-2.5-pro",
    "claude-sonnet-4",
    "gpt-4.1",
    "gemini-2.0-flash-001",
    "claude-opus-4",
    "grok-code-fast-1",
    "claude-opus-41",
    "claude-3.7-sonnet-thought",
    "gpt-5",
    "o3",
    "gpt-5-mini",
    "claude-3.7-sonnet",
    "claude-3.5-sonnet",
    "gpt-4o",
    "o4-mini",
    "o3-mini"
  ],
  "submodel": [
    "deepseek-ai/DeepSeek-V3.1",
    "deepseek-ai/DeepSeek-V3-0324",
    "deepseek-ai/DeepSeek-R1-0528",
    "openai/gpt-oss-120b",
    "Qwen/Qwen3-235B-A22B-Thinking-2507",
    "Qwen/Qwen3-235B-A22B-Instruct-2507",
    "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "zai-org/GLM-4.5-FP8",
    "zai-org/GLM-4.5-Air"
  ],
  "alibaba": [
    "qwen3-coder-plus"
  ],
  "upstage": [
    "solar-pro2",
    "solar-mini"
  ],
  "llama": [
    "groq-llama-4-maverick-17b-128e-instruct",
    "llama-3.3-70b-instruct",
    "llama-4-maverick-17b-128e-instruct-fp8",
    "llama-4-scout-17b-16e-instruct-fp8",
    "cerebras-llama-4-scout-17b-16e-instruct",
    "llama-3.3-8b-instruct",
    "cerebras-llama-4-maverick-17b-128e-instruct"
  ],
  "moonshotai_cn": [
    "kimi-k2-0905-preview",
    "kimi-k2-0711-preview",
    "kimi-k2-turbo-preview"
  ],
  "zhipuai": [
    "glm-4.5",
    "glm-4.5-flash",
    "glm-4.5v",
    "glm-4.5-air"
  ],
  "synthetic": [
    "hf:meta-llama/Llama-3.1-405B-Instruct",
    "hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "hf:meta-llama/Llama-3.1-70B-Instruct",
    "hf:meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "hf:meta-llama/Llama-3.3-70B-Instruct",
    "hf:meta-llama/Llama-3.1-8B-Instruct",
    "hf:deepseek-ai/DeepSeek-V3.1",
    "hf:deepseek-ai/DeepSeek-V3",
    "hf:deepseek-ai/DeepSeek-V3-0324",
    "hf:deepseek-ai/DeepSeek-R1",
    "hf:deepseek-ai/DeepSeek-R1-0528",
    "hf:zai-org/GLM-4.5",
    "hf:moonshotai/Kimi-K2-Instruct",
    "hf:moonshotai/Kimi-K2-Instruct-0905",
    "hf:Qwen/Qwen2.5-Coder-32B-Instruct",
    "hf:Qwen/Qwen3-Coder-480B-A35B-Instruct",
    "hf:Qwen/Qwen3-235B-A22B-Thinking-2507",
    "hf:Qwen/Qwen3-235B-A22B-Instruct-2507",
    "hf:openai/gpt-oss-120b"
  ],
  "modelscope": [
    "Qwen/Qwen3-30B-A3B-Thinking-2507",
    "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    "Qwen/Qwen3-235B-A22B-Thinking-2507",
    "Qwen/Qwen3-30B-A3B-Instruct-2507",
    "Qwen/Qwen3-235B-A22B-Instruct-2507",
    "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    "ZhipuAI/GLM-4.5",
    "moonshotai/Kimi-K2-Instruct"
  ],
  "baseten": [
    "Moonshotai-Kimi-K2-Instruct-0905",
    "Qwen-Qwen3-Coder-480B-A35B-Instruct"
  ],
  "wandb": [
    "deepseek-ai/DeepSeek-V3-0324",
    "deepseek-ai/DeepSeek-R1-0528",
    "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    "Qwen/Qwen3-235B-A22B-Thinking-2507",
    "Qwen/Qwen3-235B-A22B-Instruct-2507",
    "meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "meta-llama/Llama-3.3-70B-Instruct",
    "meta-llama/Llama-3.1-8B-Instruct",
    "microsoft/Phi-4-mini-instruct",
    "moonshotai/Kimi-K2-Instruct"
  ],
  "inference": [
    "meta/llama-3.2-3b-instruct",
    "meta/llama-3.2-1b-instruct",
    "meta/llama-3.1-8b-instruct",
    "meta/llama-3.2-11b-vision-instruct",
    "mistral/mistral-nemo-12b-instruct",
    "google/gemma-3",
    "osmosis/osmosis-structure-0.6b",
    "qwen/qwen-2.5-7b-vision-instruct",
    "qwen/qwen3-embedding-4b"
  ],
  "github_models": [
    "deepseek/deepseek-v3-0324",
    "deepseek/deepseek-r1-0528",
    "deepseek/deepseek-r1",
    "meta/meta-llama-3-8b-instruct",
    "meta/llama-3.2-90b-vision-instruct",
    "meta/llama-3.3-70b-instruct",
    "meta/meta-llama-3.1-70b-instruct",
    "meta/llama-4-maverick-17b-128e-instruct-fp8",
    "meta/meta-llama-3.1-8b-instruct",
    "meta/meta-llama-3.1-405b-instruct",
    "meta/llama-3.2-11b-vision-instruct",
    "meta/llama-4-scout-17b-16e-instruct",
    "meta/meta-llama-3-70b-instruct",
    "xai/grok-3",
    "xai/grok-3-mini",
    "openai/gpt-4.1",
    "openai/o1",
    "openai/o3",
    "openai/o1-preview",
    "openai/gpt-4o-mini",
    "openai/gpt-4.1-nano",
    "openai/gpt-4.1-mini",
    "openai/o1-mini",
    "openai/gpt-4o",
    "openai/o4-mini",
    "openai/o3-mini",
    "ai21-labs/ai21-jamba-1.5-mini",
    "ai21-labs/ai21-jamba-1.5-large",
    "microsoft/phi-3-medium-4k-instruct",
    "microsoft/phi-3.5-vision-instruct",
    "microsoft/phi-4-reasoning",
    "microsoft/phi-4",
    "microsoft/phi-3-small-8k-instruct",
    "microsoft/phi-4-mini-instruct",
    "microsoft/phi-3-mini-128k-instruct",
    "microsoft/phi-3-small-128k-instruct",
    "microsoft/mai-ds-r1",
    "microsoft/phi-3.5-moe-instruct",
    "microsoft/phi-4-multimodal-instruct",
    "microsoft/phi-4-mini-reasoning",
    "microsoft/phi-3.5-mini-instruct",
    "microsoft/phi-3-mini-4k-instruct",
    "microsoft/phi-3-medium-128k-instruct",
    "mistral-ai/mistral-small-2503",
    "mistral-ai/mistral-large-2411",
    "mistral-ai/mistral-medium-2505",
    "mistral-ai/ministral-3b",
    "mistral-ai/mistral-nemo",
    "mistral-ai/codestral-2501",
    "cohere/cohere-command-r-08-2024",
    "cohere/cohere-command-r-plus-08-2024",
    "cohere/cohere-command-a",
    "cohere/cohere-command-r",
    "cohere/cohere-command-r-plus",
    "core42/jais-30b-chat"
  ],
  "opencode": [
    "claude-sonnet-4",
    "grok-code",
    "gpt-5",
    "claude-3.5-haiku",
    "kimi-k2",
    "claude-opus-4.1",
    "qwen3-coder"
  ],
  "nvidia": [
    "mistral-small-3.1-24b-instruct-2503",
    "llama-3.3-nemotron-super-49b-v1.5",
    "qwen3-235b-a22b",
    "deepseek-v3.1",
    "flux_1-dev",
    "cosmos-nemotron-34b",
    "whisper-large-v3",
    "qwen3-coder-480b-a35b-instruct",
    "phi-4-multimodal-instruct",
    "parakeet-tdt-0.6b-v2",
    "llama-3.1-nemotron-ultra-253b-v1",
    "deepseek-r1",
    "nemoretriever-ocr-v1",
    "gemma-3-27b-it"
  ],
  "huggingface": [
    "deepseek-ai/Deepseek-V3-0324",
    "deepseek-ai/DeepSeek-R1-0528",
    "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    "Qwen/Qwen3-235B-A22B-Thinking-2507",
    "zai-org/GLM-4.5-Air",
    "zai-org/GLM-4.5",
    "moonshotai/Kimi-K2-Instruct"
  ],
  "inception": [
    "mercury-coder",
    "mercury"
  ],
  "chutes": [
    "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "deepseek-ai/DeepSeek-V3.1",
    "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
    "deepseek-ai/DeepSeek-V3.1:THINKING",
    "deepseek-ai/DeepSeek-V3-0324",
    "deepseek-ai/DeepSeek-R1-0528",
    "openai/gpt-oss-120b",
    "chutesai/Devstral-Small-2505",
    "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
    "Qwen/Qwen3-235B-A22B-Thinking-2507",
    "Qwen/Qwen3-30B-A3B-Instruct-2507",
    "Qwen/Qwen3-30B-A3B",
    "Qwen/Qwen3-235B-A22B-Instruct-2507",
    "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "zai-org/GLM-4.5-FP8",
    "zai-org/GLM-4.5-Air",
    "tngtech/DeepSeek-TNG-R1T2-Chimera",
    "tngtech/DeepSeek-R1T-Chimera",
    "moonshotai/Kimi-K2-Instruct-75k",
    "moonshotai/Kimi-VL-A3B-Thinking",
    "moonshotai/Kimi-K2-Instruct-0905",
    "moonshotai/Kimi-Dev-72B"
  ],
  "lmstudio": [
    "openai/gpt-oss-20b",
    "qwen/qwen3-coder-30b",
    "qwen/qwen3-30b-a3b-2507"
  ],
  "zai": [
    "glm-4.5-air",
    "glm-4.5v",
    "glm-4.5-flash",
    "glm-4.5"
  ],
  "fastrouter": [
    "deepseek-ai/deepseek-r1-distill-llama-70b",
    "anthropic/claude-sonnet-4",
    "anthropic/claude-opus-4.1",
    "openai/gpt-5-nano",
    "openai/gpt-4.1",
    "openai/gpt-oss-20b",
    "openai/gpt-5",
    "openai/gpt-5-mini",
    "openai/gpt-oss-120b",
    "x-ai/grok-4",
    "google/gemini-2.5-pro",
    "google/gemini-2.5-flash",
    "qwen/qwen3-coder",
    "moonshotai/kimi-k2"
  ],
  "morph": [
    "auto",
    "morph-v3-fast",
    "morph-v3-large"
  ],
  "moonshotai": [
    "kimi-k2-turbo-preview",
    "kimi-k2-0711-preview",
    "kimi-k2-0905-preview"
  ],
  "openai": [
    "gpt-5-nano",
    "o3-pro",
    "codex-mini-latest",
    "gpt-4.1",
    "gpt-4-turbo",
    "o1",
    "o3-deep-research",
    "gpt-5",
    "o1-pro",
    "o3",
    "gpt-5-chat-latest",
    "gpt-5-mini",
    "o1-preview",
    "o4-mini-deep-research",
    "gpt-4o-mini",
    "gpt-4.1-nano",
    "gpt-4.1-mini",
    "o1-mini",
    "gpt-4o",
    "gpt-4",
    "gpt-3.5-turbo",
    "o4-mini",
    "o3-mini"
  ],
  "anthropic": [
    "claude-3-7-sonnet-20250219",
    "claude-opus-4-1-20250805",
    "claude-3-haiku-20240307",
    "claude-3-5-haiku-20241022",
    "claude-opus-4-20250514",
    "claude-3-5-sonnet-20241022",
    "claude-3-5-sonnet-20240620",
    "claude-3-sonnet-20240229",
    "claude-sonnet-4-20250514",
    "claude-3-opus-20240229"
  ],
  "groq": [
    "llama-3.1-8b-instant",
    "qwen-qwq-32b",
    "llama3-70b-8192",
    "deepseek-r1-distill-llama-70b",
    "llama3-8b-8192",
    "gemma2-9b-it",
    "llama-3.3-70b-versatile",
    "mistral-saba-24b",
    "llama-guard-3-8b",
    "openai/gpt-oss-20b",
    "openai/gpt-oss-120b",
    "meta-llama/llama-guard-4-12b",
    "meta-llama/llama-4-maverick-17b-128e-instruct",
    "meta-llama/llama-4-scout-17b-16e-instruct",
    "qwen/qwen3-32b",
    "moonshotai/kimi-k2-instruct-0905",
    "moonshotai/kimi-k2-instruct"
  ]
} as const;

/**
 * Type definitions for autocomplete support
 */
export type ProviderModels = typeof PROVIDER_MODELS;
export type Provider = keyof ProviderModels;
export type ModelForProvider<P extends Provider> = ProviderModels[P][number];

/**
 * OpenAI-compatible model ID type
 * Full provider/model paths (e.g., "openai/gpt-4o", "anthropic/claude-3-5-sonnet-20241022")
 */
export type OpenAICompatibleModelId = {[P in Provider]: `${P}/${ModelForProvider<P>}`}[Provider];



/**
 * Get provider configuration by provider ID
 */
export function getProviderConfig(providerId: string): ProviderConfig | undefined {
  return PROVIDER_REGISTRY[providerId as keyof typeof PROVIDER_REGISTRY];
}

/**
 * Check if a provider is registered
 */
export function isProviderRegistered(providerId: string): boolean {
  return providerId in PROVIDER_REGISTRY;
}

/**
 * Get all registered provider IDs
 */
export function getRegisteredProviders(): string[] {
  return Object.keys(PROVIDER_REGISTRY);
}

/**
 * Get available models for a specific provider
 */
export function getModelsForProvider(providerId: Provider): readonly string[] {
  return PROVIDER_MODELS[providerId] ?? [];
}

/**
 * Get models for a provider by string (runtime version)
 */
export function getModelsForProviderString(providerId: string): readonly string[] {
  const models = (PROVIDER_MODELS as any)[providerId];
  return models ?? [];
}

/**
 * Parse a model string to extract provider and model ID
 * Examples:
 *   "openai/gpt-4o" -> { provider: "openai", modelId: "gpt-4o" }
 *   "chutes/Qwen/Qwen3-235B" -> { provider: "chutes", modelId: "Qwen/Qwen3-235B" }
 *   "gpt-4o" -> { provider: null, modelId: "gpt-4o" }
 */
export function parseModelString(modelString: string): { provider: string | null; modelId: string } {
  const firstSlashIndex = modelString.indexOf('/');
  
  if (firstSlashIndex !== -1) {
    // Has at least one slash - extract provider and rest as model ID
    const provider = modelString.substring(0, firstSlashIndex);
    const modelId = modelString.substring(firstSlashIndex + 1);
    
    if (provider && modelId) {
      return {
        provider,
        modelId,
      };
    }
  }
  
  // No slash or invalid format
  return {
    provider: null,
    modelId: modelString,
  };
}

/**
 * Type guard to check if a string is a valid OpenAI-compatible model ID
 */
export function isValidModelId(modelId: string): modelId is OpenAICompatibleModelId {
  // Check if it's just a provider name
  if (modelId in PROVIDER_REGISTRY) {
    return true;
  }
  
  // Check if it's a provider/model combination
  const parsed = parseModelString(modelId);
  if (!parsed.provider) return false;
  
  const models = getModelsForProviderString(parsed.provider);
  return models.includes(parsed.modelId);
}
